{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapreparation\n",
    "\n",
    "Prepare and save the data in ./data/train/ and ./data/valid/. This only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import prepare_data\n",
    "\n",
    "prepare_data(100,range(1,300),True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Reconstruction\n",
    "\n",
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explore import Optim\n",
    "device = 'cuda'\n",
    "angles = 100\n",
    "net_file = \"network_100a.pt\"\n",
    "optim = Optim(angles,name=net_file,device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization using Bi-level optimization\n",
    "Select an image by choosing an *image id* and insert the desired value for *m*.<br>\n",
    "Select the *Sparse_rep_learning_rate* for learning rate of Sparsity network and *Sparse_rep_number_of_epochs* number of epochs to learn sparsity network<br>\n",
    "Select the *Dictionary_learnin_rate* for learning rate of Dicitonary network and *Dictionary_number_of_epochs* number of epochs to learn Dictionary network<br>\n",
    "Select an *number of atoms* in dictionary.\n",
    "Select *l1_lambda* for L1 Regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = {\n",
    "        \"rotate\": list(range(0, 360, 360//4)),\n",
    "        \"zoom\": lambda x: [x-2, x, x+2],\n",
    "        \"shift\": [0]\n",
    "    }\n",
    "\n",
    "image_id = 169\n",
    "m = 1.0 \n",
    "patchsize = 2\n",
    "number_of_atoms = 10\n",
    "Sparse_rep_learning_rate = 1e-3\n",
    "Sparse_rep_number_of_epochs = 3\n",
    "Dictionary_learnin_rate = 1e-5\n",
    "Dictionary_number_of_epochs = 3\n",
    "l1_lambda = 4e-3\n",
    "\n",
    "results = optim.optimize_GD(dataid= image_id, epochs=1000, mask_w=11, w_r=1.0, w_c=1.0, w_tv=0.01, lr=1, opt_to = m, perms=permutation,\n",
    "                            lr_Dict =Dictionary_learnin_rate, epochs_Dict=Dictionary_number_of_epochs,\n",
    "                            lr_SV=Sparse_rep_learning_rate, epochs_SP=Sparse_rep_number_of_epochs,\n",
    "                            l1_lambda=l1_lambda, patchsize=patchsize, number_of_atoms=number_of_atoms\n",
    "                            )\n",
    "\n",
    "dict_loss, spars_network_loss, psnrs, xt, errors, losses, losses_r, losses_c, preds, stopiter, data_specs = results\n",
    "tmean, tvar, slice, sino, low_dose, loc, malig, angles, end_sino, ld_sino = data_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "\n",
    "### Plot of the interior and the exterior error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare errors\n",
    "errors2=list(zip(*errors))\n",
    "errors3=list(zip(*errors2[1]))\n",
    "error_nodule = torch.stack(errors3[0])[:,0,0]\n",
    "error_sur = torch.stack(errors3[1])[:,0,0]\n",
    "\n",
    "# plot errors\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(error_nodule)\n",
    "plt.plot(error_sur)\n",
    "plt.legend([\"error nodule\", \"error surrounding\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the PSNR of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot psnrs\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(psnrs, linewidth=0.5)\n",
    "plt.legend([\"PSNR of each iteration\"])\n",
    "plt.savefig(f'res300/{image_id}/{number_of_atoms}/{patchsize}/{m}/WF-PSNR for non_coeff.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the losses of Dictionary Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot helping networks losses\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(dict_loss, linewidth=0.5)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.legend([\"Dictionary Network Lossses\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the losses of Sparse Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(spars_network_loss , linewidth=0.5)\n",
    "plt.legend([\"Sparse Network Lossses\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the (cropped) reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset as ds\n",
    "\n",
    "result_xt = (ds.crop_center(xt, loc, size=optim.nosz*3))[0,0]\n",
    "\n",
    "fig, (ax0) = plt.subplots(1,1)\n",
    "ax0.axis('off')\n",
    "ax0.imshow(result_xt ,cmap = 'viridis', interpolation='bicubic')\n",
    "plt.savefig(f'res300/{image_id}/{number_of_atoms}/{patchsize}/{m}/WF-Image for non_coeff.png')\n",
    "\n",
    "fig, (ax0) = plt.subplots(1,1, figsize=(5,3))\n",
    "ax0.plot(preds)\n",
    "plt.savefig(f'res300/{image_id}/{number_of_atoms}/{patchsize}/{m}/WF-Prediction for non_coeff.png')\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the loss and the network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(15,4))\n",
    "\n",
    "\n",
    "ax0.plot(losses)\n",
    "ax0.plot(losses_r)\n",
    "ax0.plot(losses_c)\n",
    "ax0.legend([\"loss\",\"loss E1\",\"loss E2(1)\"])\n",
    "ax0.set_title(\"Losses\")\n",
    "\n",
    "ax1.plot(preds)\n",
    "ax1.set_title(f\"Network prediction\")\n",
    "plt.savefig(f'Res-normal/{image_id}/{m}/WF-Prediction.png')\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapreparation\n",
    "\n",
    "Prepare and save the data in ./data/train/ and ./data/valid/. This only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'radon_transformation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17271137eb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mradon_transformation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mradon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdicom_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScanotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'radon_transformation'"
     ]
    }
   ],
   "source": [
    "from dataset import prepare_data\n",
    "prepare_data(100,range(1,300),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Reconstruction\n",
    "\n",
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niaruhi/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DL.KSVD_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexplore\u001b[39;00m \u001b[39mimport\u001b[39;00m Optim\n\u001b[1;32m      2\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m angles \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[0;32m~/explore.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGD_MODEL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSparsity\u001b[39;00m \u001b[39mimport\u001b[39;00m Sparse_net\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGD_MODEL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDictionary\u001b[39;00m \u001b[39mimport\u001b[39;00m Dictupdate\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mKSVD_MODEL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDenoising_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m Dictionary_Learning \u001b[39mas\u001b[39;00m KSVD_dictionary\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m BasicResnet\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n",
      "File \u001b[0;32m~/DL/KSVD_MODEL/Denoising_helper.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mKSVD_model\u001b[39;00m \u001b[39mimport\u001b[39;00m ApproximateKSVD\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    Choose a set of training images that are similar to the noisy image you want to denoise.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m    Extract small image patches from the training images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m'''\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DL.KSVD_model'"
     ]
    }
   ],
   "source": [
    "from explore import Optim\n",
    "device = 'cuda'\n",
    "angles = 100\n",
    "net_file = \"network_100a.pt\"\n",
    "optim = Optim(angles,name=net_file,device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization using KSVD-Model and Orthogonal Matchin pursuit\n",
    "Select an image by choosing an *image id* and insert the desired value for *m*.<br>\n",
    "Select the *number of coefficients that can be nonezeros* in sparse representation that is allowed.<br>\n",
    "*number of atoms* in dictionary.<br>\n",
    "Select *patch size* for patchifying the image  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image id :100-0.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m image_id, m \u001b[39min\u001b[39;00m product([\u001b[39m*\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m,\u001b[39m299\u001b[39m)],[\u001b[39m0.0\u001b[39m, \u001b[39m0.6\u001b[39m,\u001b[39m1.0\u001b[39m]):\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimage id :\u001b[39m\u001b[39m{\u001b[39;00mimage_id\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     results \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39;49moptimize_normal(image_id, epochs\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m, mask_w\u001b[39m=\u001b[39;49m\u001b[39m11\u001b[39;49m, w_r\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, w_c\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, w_tv\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, opt_to \u001b[39m=\u001b[39;49m m, perms\u001b[39m=\u001b[39;49mpermutation)\n\u001b[1;32m     17\u001b[0m     xt, errors, losses, losses_r, losses_c, preds, stopiter, data_specs \u001b[39m=\u001b[39m results\n\u001b[1;32m     18\u001b[0m     tmean, tvar, \u001b[39mslice\u001b[39m, sino, low_dose, loc, malig, angles, end_sino, ld_sino \u001b[39m=\u001b[39m data_specs\n",
      "File \u001b[0;32m~/explore.py:621\u001b[0m, in \u001b[0;36mOptim.optimize_normal\u001b[0;34m(self, dataid, epochs, mask_w, w_r, w_c, w_tv, lr, opt_to, perms)\u001b[0m\n\u001b[1;32m    618\u001b[0m mean_loss_prev \u001b[39m=\u001b[39m \u001b[39m1e9\u001b[39m\n\u001b[1;32m    620\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 621\u001b[0m     tmean, tstd, \u001b[39mslice\u001b[39m, sino, low_dose, loc, malig, angles \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepared_data(dataid)\n\u001b[1;32m    622\u001b[0m     ld_sino \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mradon_t(low_dose\u001b[39m.\u001b[39mcpu()) \u001b[39m-\u001b[39m sino\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m    624\u001b[0m \u001b[39m# pretrain on E_1\u001b[39;00m\n",
      "File \u001b[0;32m~/explore.py:87\u001b[0m, in \u001b[0;36mOptim.prepared_data\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m''' Load and prepare an data item. Define the radon loss E_1.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[39margs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    the malignancy of the nodule and the number of angles\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m# get data\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mslice\u001b[39m, _, _, loc, malig, angles \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n\u001b[1;32m     88\u001b[0m malig \u001b[39m=\u001b[39m malig[\u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     89\u001b[0m loc \u001b[39m=\u001b[39m loc[\u001b[39mNone\u001b[39;00m]\n",
      "File \u001b[0;32m~/dataset.py:32\u001b[0m, in \u001b[0;36mIDLC_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m''' Returns: full dose, low dose, sinogram, nodule pos, angles, malignancy\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     data_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[idx]\n\u001b[1;32m     33\u001b[0m     \u001b[39mslice\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data_item[\u001b[39m'\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     34\u001b[0m     sino \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data_item[\u001b[39m'\u001b[39m\u001b[39msino\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39mNone\u001b[39;00m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "permutation = {\n",
    "        \"rotate\": list(range(0, 360, 360//4)),\n",
    "        \"zoom\": lambda x: [x-2, x, x+2],\n",
    "        \"shift\": [0]\n",
    "    }\n",
    "\n",
    "image_id = 135\n",
    "non_zero_coefs = 1\n",
    "number_of_atoms = 3\n",
    "m = 1.0\n",
    "patchsize = 2\n",
    "\n",
    "results = optim.optimize_ksvd(image_id, epochs=3000, mask_w=11., w_r=1.0, w_c=1.0, w_tv=0.01, lr=1,\n",
    "                                  opt_to=m, perms=permutation,\n",
    "                                  non_zero_coefs=non_zero_coefs, number_of_atoms=number_of_atoms,\n",
    "                                  patchsize=patchsize\n",
    "                                  )\n",
    "psnrs, xt, errors, losses, losses_r, losses_c, preds, stopiter, data_specs = results\n",
    "tmean, tvar, slice, sino, low_dose, loc, malig, angles, end_sino, ld_sino = data_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "\n",
    "### Plot of the interior and the exterior error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare errors\n",
    "errors2=list(zip(*errors))\n",
    "errors3=list(zip(*errors2[1])) \n",
    "error_nodule = torch.stack(errors3[0])[:,0,0]\n",
    "error_sur = torch.stack(errors3[1])[:,0,0]\n",
    "\n",
    "# plot errors\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(error_nodule)\n",
    "plt.plot(error_sur)\n",
    "plt.title(\"Error values e0 and e1\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.legend([\"error nodule\", \"error surrounding\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PSNR of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot psnrs\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(psnrs, linewidth=0.5)\n",
    "plt.title(\"PSNR of each epoch\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.legend([\"PSNR\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the (cropped) reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset as ds\n",
    "\n",
    "result_xt = (ds.crop_center(xt, loc, size=optim.nosz*3))[0,0]\n",
    "startg_xt = (ds.crop_center(low_dose, loc, size=optim.nosz*3))[0,0]\n",
    "fig, (ax0,ax1) = plt.subplots(1,2)\n",
    "ax0.axis('off')\n",
    "ax0.imshow(startg_xt)\n",
    "ax0.set_title(\"reconstr. filtered backpr.\")\n",
    "ax1.axis('off')\n",
    "ax1.imshow(result_xt ,cmap = 'viridis', interpolation='bicubic')\n",
    "ax1.set_title(f\"reconstr. m={m}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the loss and the network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(15,4))\n",
    "\n",
    "ax0.plot(losses) \n",
    "ax0.plot(losses_r)\n",
    "ax0.plot(losses_c)\n",
    "ax0.legend([\"loss\",\"loss E1\",\"loss E2(1)\"])\n",
    "ax0.set_title(\"Losses\")\n",
    "\n",
    "ax1.plot(preds)\n",
    "ax1.set_title(f\"Network prediction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
